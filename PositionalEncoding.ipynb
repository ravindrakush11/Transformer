{
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iom_4q-pp1Np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "\n",
        "class PositionalEncoding(torch.nn.Module):\n",
        "  def __init__(self, d_model, max_len = 5000):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "\n",
        "    # Create a matrix of shape (max_len, d_model) with zero values\n",
        "    pe = torch.zeros(max_len, d_model)\n",
        "\n",
        "    # Create a vector of shape (max_len) representing position indices\n",
        "    position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "    # Division term of for the sine and cosine function\n",
        "    div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000)/d_model))\n",
        "\n",
        "    # Apply sine for even indices\n",
        "    pe[:, 0::2]  =torch.sin(position*div_term)\n",
        "\n",
        "    # Apply cosine for odd indices\n",
        "    pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "    pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "\n",
        "    self.register_buffer('pe', pe)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x + self.pe[: x.size(0), :] # positional encoding to input embedding\n"
      ],
      "metadata": {
        "id": "dVrlIbHlAhLV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_positional_encoding():\n",
        "  d_model = 512\n",
        "  max_len = 60\n",
        "  batch_size = 2\n",
        "\n",
        "  pos_enc = PositionalEncoding(d_model, max_len)\n",
        "\n",
        "  dummy_input = torch.zeros(max_len, batch_size, d_model)\n",
        "\n",
        "  output = pos_enc(dummy_input)\n",
        "\n",
        "  print(\"Positional Encodings: \")\n",
        "  print(output)\n",
        "  print(\"shape: \",output.size())\n",
        "test_positional_encoding()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbzYTexXV2zq",
        "outputId": "a101bf9b-a09b-48f4-f9e4-577b94559de2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positional Encodings: \n",
            "tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
            "           0.0000e+00,  1.0000e+00],\n",
            "         [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
            "           0.0000e+00,  1.0000e+00]],\n",
            "\n",
            "        [[ 8.4147e-01,  5.4030e-01,  8.2186e-01,  ...,  1.0000e+00,\n",
            "           1.0366e-04,  1.0000e+00],\n",
            "         [ 8.4147e-01,  5.4030e-01,  8.2186e-01,  ...,  1.0000e+00,\n",
            "           1.0366e-04,  1.0000e+00]],\n",
            "\n",
            "        [[ 9.0930e-01, -4.1615e-01,  9.3641e-01,  ...,  1.0000e+00,\n",
            "           2.0733e-04,  1.0000e+00],\n",
            "         [ 9.0930e-01, -4.1615e-01,  9.3641e-01,  ...,  1.0000e+00,\n",
            "           2.0733e-04,  1.0000e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 4.3616e-01,  8.9987e-01, -9.9997e-01,  ...,  9.9998e-01,\n",
            "           5.9088e-03,  9.9998e-01],\n",
            "         [ 4.3616e-01,  8.9987e-01, -9.9997e-01,  ...,  9.9998e-01,\n",
            "           5.9088e-03,  9.9998e-01]],\n",
            "\n",
            "        [[ 9.9287e-01,  1.1918e-01, -5.6324e-01,  ...,  9.9998e-01,\n",
            "           6.0124e-03,  9.9998e-01],\n",
            "         [ 9.9287e-01,  1.1918e-01, -5.6324e-01,  ...,  9.9998e-01,\n",
            "           6.0124e-03,  9.9998e-01]],\n",
            "\n",
            "        [[ 6.3674e-01, -7.7108e-01,  3.5823e-01,  ...,  9.9998e-01,\n",
            "           6.1161e-03,  9.9998e-01],\n",
            "         [ 6.3674e-01, -7.7108e-01,  3.5823e-01,  ...,  9.9998e-01,\n",
            "           6.1161e-03,  9.9998e-01]]])\n",
            "shape:  torch.Size([60, 2, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J0k9H5QUXW_I"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yjwTTG8BXkM4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcQdC05L05JG/GXnv5D3Gm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}